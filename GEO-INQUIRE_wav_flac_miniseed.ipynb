{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Audio Processing Tool for WAV Files ‚Äì EMSO & EIDA Compliance\n",
        "\n",
        "**Author:** Silvana Neves\n",
        "\n",
        "### Overview\n",
        "\n",
        "This tool processes WAV audio files to ensure compliance with EMSO (European Multidisciplinary Seafloor and Water Column Observatory) and EIDA (European Integrated Data Archive) standards. It performs downsampling, format conversion, and metadata embedding, thereby standardizing seismic and acoustic data for efficient storage, interoperability, and sharing. The tool has been developed in alignment with the requirements of the GEO-INQUIRE project and complies with the Marine Strategy Framework Directive (MSFD).\n",
        "\n",
        "### Key Features\n",
        "\n",
        "- **File Selection and Batch Processing:** Select individual WAV files or entire directories\n",
        "- **Automated Date Extraction:** Recording start time automatically derived from WAV filename\n",
        "- **UTC Offset Adjustment:** User-specified UTC offset applied to all metadata timestamps\n",
        "- **Downsampling and Low-Pass Filtering:** Audio normalized and downsampled to 300 Hz\n",
        "- **Conversion to FLAC with Embedded Metadata:** EMSO-compliant metadata embedded in FLAC files\n",
        "- **Conversion to MiniSEED:** FLAC files converted to MiniSEED format\n",
        "- **Generation of EIDA-Compliant XML:** StationXML metadata files generated automatically\n",
        "- **Graphical User Interface (GUI):** Tkinter-based interface for easy operation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "%pip install numpy soundfile scipy pydub mutagen obspy lxml matplotlib Pillow plotly python-dateutil\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup FFmpeg paths (adjust if needed)\n",
        "import os\n",
        "from pydub import AudioSegment\n",
        "from pydub.utils import which\n",
        "import shutil\n",
        "\n",
        "# Try to find FFmpeg\n",
        "ffmpeg_exe = None\n",
        "ffprobe_exe = None\n",
        "\n",
        "# Check environment variables first\n",
        "ffmpeg_exe = os.environ.get('FFMPEG_EXE', None)\n",
        "ffprobe_exe = os.environ.get('FFPROBE_EXE', None)\n",
        "\n",
        "# Check if in PATH\n",
        "if not ffmpeg_exe or not ffprobe_exe:\n",
        "    ffmpeg_path = shutil.which(\"ffmpeg\")\n",
        "    ffprobe_path = shutil.which(\"ffprobe\")\n",
        "    if ffmpeg_path and ffprobe_path:\n",
        "        ffmpeg_exe = ffmpeg_path\n",
        "        ffprobe_exe = ffprobe_path\n",
        "\n",
        "# Try common Windows paths\n",
        "if not ffmpeg_exe or not ffprobe_exe:\n",
        "    common_paths = [\n",
        "        r\"C:\\ffmpeg\\bin\",\n",
        "        r\"C:\\Program Files\\ffmpeg\\bin\",\n",
        "        r\"C:\\Program Files (x86)\\ffmpeg\\bin\",\n",
        "    ]\n",
        "    for path in common_paths:\n",
        "        test_ffmpeg = os.path.join(path, \"ffmpeg.exe\")\n",
        "        test_ffprobe = os.path.join(path, \"ffprobe.exe\")\n",
        "        if os.path.exists(test_ffmpeg) and os.path.exists(test_ffprobe):\n",
        "            ffmpeg_exe = test_ffmpeg\n",
        "            ffprobe_exe = test_ffprobe\n",
        "            if path not in os.environ.get(\"PATH\", \"\"):\n",
        "                os.environ[\"PATH\"] += os.pathsep + path\n",
        "            break\n",
        "\n",
        "# Set up AudioSegment\n",
        "if ffmpeg_exe and ffprobe_exe:\n",
        "    AudioSegment.converter = ffmpeg_exe\n",
        "    AudioSegment.ffprobe = ffprobe_exe\n",
        "    os.environ[\"FFMPEG_BINARY\"] = ffmpeg_exe\n",
        "    print(f\"‚úì FFmpeg found: {ffmpeg_exe}\")\n",
        "    print(f\"‚úì FFprobe found: {ffprobe_exe}\")\n",
        "else:\n",
        "    print(\"‚ö† Warning: FFmpeg not found. Please install FFmpeg and set paths.\")\n",
        "    print(\"  Download from: https://ffmpeg.org/download.html\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import all required libraries\n",
        "import os\n",
        "import tkinter as tk\n",
        "from tkinter import filedialog, messagebox, ttk, Toplevel, Label\n",
        "import webbrowser\n",
        "from datetime import datetime, timedelta\n",
        "import time\n",
        "import re\n",
        "import tempfile\n",
        "import threading\n",
        "\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "from scipy.signal import firwin, lfilter, resample\n",
        "from pydub import AudioSegment\n",
        "from mutagen.flac import FLAC\n",
        "import obspy\n",
        "from obspy.core import UTCDateTime\n",
        "from obspy.core.inventory import (\n",
        "    Inventory, Network, Station, Channel, Response, InstrumentSensitivity, Site\n",
        ")\n",
        "import plotly.graph_objects as go\n",
        "from dateutil import parser\n",
        "from lxml import etree\n",
        "\n",
        "# Global configuration\n",
        "FINAL_SAMPLING_RATE = 300  # Final sampling rate (Hz)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==================== CORE PROCESSING FUNCTIONS ====================\n",
        "\n",
        "def extract_datetime_from_filename(filename):\n",
        "    \"\"\"\n",
        "    Automatically extracts a datetime from the filename.\n",
        "    \n",
        "    1. First, tries to match a full datetime with explicit separators, e.g.:\n",
        "       \"2024-05-17_09-25-33\" ‚Üí returns a datetime with date and time.\n",
        "    2. If that fails, it tries to match a compact format like \"20180726_141241\".\n",
        "    3. Otherwise, it falls back to fuzzy parsing of the entire filename.\n",
        "    \n",
        "    The returned datetime is naive (tzinfo removed).\n",
        "    \"\"\"\n",
        "    # Remove file extension\n",
        "    name = re.sub(r'\\.\\w+$', '', filename)\n",
        "    \n",
        "    # 1. Try full datetime with explicit separators: e.g. \"2024-05-17_09-25-33\"\n",
        "    pattern_full = r'(\\d{4}[-]\\d{2}[-]\\d{2})[ _](\\d{2}[-]\\d{2}[-]\\d{2})'\n",
        "    match = re.search(pattern_full, name)\n",
        "    if match:\n",
        "        try:\n",
        "            date_part = match.group(1)\n",
        "            time_part = match.group(2).replace('-', ':')\n",
        "            dt_str = f\"{date_part} {time_part}\"\n",
        "            dt = datetime.strptime(dt_str, \"%Y-%m-%d %H:%M:%S\")\n",
        "            return dt\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    # 2. Try compact datetime: e.g. \"20180726_141241\"\n",
        "    pattern_compact = r'(\\d{8})[ _](\\d{6})'\n",
        "    match = re.search(pattern_compact, name)\n",
        "    if match:\n",
        "        try:\n",
        "            date_part = match.group(1)\n",
        "            time_part = match.group(2)\n",
        "            dt_str = f\"{date_part} {time_part}\"\n",
        "            dt = datetime.strptime(dt_str, \"%Y%m%d %H%M%S\")\n",
        "            return dt\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    # 3. Fallback: fuzzy parse entire filename\n",
        "    try:\n",
        "        dt = parser.parse(name, fuzzy=True)\n",
        "        return dt.replace(tzinfo=None)\n",
        "    except Exception:\n",
        "        return datetime.utcnow()\n",
        "\n",
        "def generate_start_end_time(wav_file_name, duration_seconds):\n",
        "    \"\"\"\n",
        "    Extracts the start time from the WAV filename using the AI-powered extraction.\n",
        "    If no valid timestamp is found, uses the current UTC time.\n",
        "    Computes the end time as start time plus the file's duration.\n",
        "    Returns start and end times in ISO format.\n",
        "    \"\"\"\n",
        "    dt = extract_datetime_from_filename(wav_file_name)\n",
        "    start_time = UTCDateTime(dt.isoformat())\n",
        "    end_time = start_time + duration_seconds\n",
        "    return start_time.isoformat(), end_time.isoformat()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Signal processing functions\n",
        "\n",
        "def plot_signals(original_signal, filtered_signal, downsampled_signal, original_rate, target_rate):\n",
        "    \"\"\"Plot comparison of original, filtered, and downsampled signals.\"\"\"\n",
        "    original_samples_to_plot = original_rate\n",
        "    downsampled_samples_to_plot = target_rate\n",
        "\n",
        "    original_signal_norm = (original_signal / np.max(np.abs(original_signal))\n",
        "                              if np.max(np.abs(original_signal)) != 0 else original_signal)\n",
        "    filtered_signal_norm = (filtered_signal / np.max(np.abs(filtered_signal))\n",
        "                            if np.max(np.abs(filtered_signal)) != 0 else filtered_signal)\n",
        "    downsampled_signal_norm = (downsampled_signal / np.max(np.abs(downsampled_signal))\n",
        "                               if np.max(np.abs(downsampled_signal)) != 0 else downsampled_signal)\n",
        "\n",
        "    t_original = np.linspace(0, 1, original_samples_to_plot, endpoint=False)\n",
        "    t_filtered = np.linspace(0, 1, original_samples_to_plot, endpoint=False)\n",
        "    t_downsampled = np.linspace(0, 1, downsampled_samples_to_plot, endpoint=False)\n",
        "\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatter(x=t_original, y=original_signal_norm[:original_samples_to_plot],\n",
        "                             mode='lines', name='Original Signal'))\n",
        "    fig.add_trace(go.Scatter(x=t_filtered, y=filtered_signal_norm[:original_samples_to_plot],\n",
        "                             mode='lines', name='Filtered Signal'))\n",
        "    fig.add_trace(go.Scatter(x=t_downsampled, y=downsampled_signal_norm[:downsampled_samples_to_plot],\n",
        "                             mode='lines+markers', name=f'Downsampled Signal ({FINAL_SAMPLING_RATE} Hz)',\n",
        "                             marker=dict(color='gold')))\n",
        "    for i in range(downsampled_samples_to_plot):\n",
        "        filtered_index = int(i * (original_rate / target_rate))\n",
        "        fig.add_trace(go.Scatter(x=[t_downsampled[i], t_filtered[filtered_index]],\n",
        "                                 y=[downsampled_signal_norm[i], filtered_signal_norm[filtered_index]],\n",
        "                                 mode='lines', line=dict(color='green', dash='dash'),\n",
        "                                 showlegend=False))\n",
        "    fig.update_layout(\n",
        "        title='First Second of the first file: Signal Downsampling and Interpolation',\n",
        "        xaxis_title='Time [s]',\n",
        "        yaxis_title='Amplitude',\n",
        "        legend=dict(yanchor=\"top\", y=0.99, xanchor=\"left\", x=0.01),\n",
        "        template=\"plotly_white\"\n",
        "    )\n",
        "    fig.show()\n",
        "\n",
        "def get_wav_info(file_path):\n",
        "    \"\"\"Read WAV file and return sample rate and data.\"\"\"\n",
        "    if not os.path.exists(file_path):\n",
        "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
        "    data, rate = sf.read(file_path)\n",
        "    if not (8000 <= rate <= 400000):\n",
        "        raise ValueError(f\"Unrealistic sample rate {rate} detected in file {file_path}.\")\n",
        "    return rate, data\n",
        "\n",
        "def downsample_wav(data, original_rate, target_rate=FINAL_SAMPLING_RATE):\n",
        "    \"\"\"\n",
        "    Downsample audio data with low-pass filtering.\n",
        "    Returns (downsampled_data, filtered_data).\n",
        "    \"\"\"\n",
        "    if original_rate == target_rate:\n",
        "        return data, data\n",
        "    \n",
        "    # Normalize\n",
        "    max_val = np.max(np.abs(data))\n",
        "    if max_val == 0:\n",
        "        max_val = 1\n",
        "    data = data / max_val\n",
        "    \n",
        "    # Design low-pass FIR filter\n",
        "    cutoff = min(150, 0.5 * target_rate)\n",
        "    numtaps = 101\n",
        "    fir_filter = firwin(numtaps, cutoff / (0.5 * original_rate))\n",
        "    filtered_data = lfilter(fir_filter, 1.0, data)\n",
        "    \n",
        "    # Downsample in chunks to avoid memory issues\n",
        "    chunk_size = 1000000\n",
        "    chunks = []\n",
        "    for i in range(0, len(filtered_data), chunk_size):\n",
        "        chunk = filtered_data[i:i + chunk_size]\n",
        "        chunk_downsampled = resample(chunk, int(len(chunk) * (target_rate / original_rate)))\n",
        "        chunks.append(chunk_downsampled)\n",
        "    \n",
        "    downsampled_data = np.concatenate(chunks)\n",
        "    downsampled_data = downsampled_data * np.iinfo(np.int16).max\n",
        "    downsampled_data = downsampled_data.astype(np.int16)\n",
        "    return downsampled_data, filtered_data\n",
        "\n",
        "def convert_data_format(data):\n",
        "    \"\"\"Convert data to int16 format.\"\"\"\n",
        "    if data.dtype != np.int16:\n",
        "        data = (data * np.iinfo(np.int16).max).astype(np.int16)\n",
        "    return data\n",
        "\n",
        "def extract_times_from_wav(file_path):\n",
        "    \"\"\"\n",
        "    Extract start and end times from WAV filename.\n",
        "    Returns (start_time, end_time) as UTCDateTime objects.\n",
        "    \"\"\"\n",
        "    base_name = os.path.basename(file_path)\n",
        "    rate, data = get_wav_info(file_path)\n",
        "    duration = len(data) / rate\n",
        "    if duration > 86400:\n",
        "        raise ValueError(f\"File {file_path} has an implausibly long duration ({duration} seconds).\")\n",
        "    start_iso, end_iso = generate_start_end_time(base_name, duration)\n",
        "    start_time = UTCDateTime(start_iso)\n",
        "    end_time = UTCDateTime(end_iso)\n",
        "    return start_time, end_time\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# File conversion functions\n",
        "\n",
        "def convert_wav_to_flac(wav_file_path, flac_file_path):\n",
        "    \"\"\"Convert WAV file to FLAC format.\"\"\"\n",
        "    audio = AudioSegment.from_file(wav_file_path, format=\"wav\")\n",
        "    audio.export(flac_file_path, format=\"flac\")\n",
        "\n",
        "def add_metadata_to_flac(flac_file_path, metadata):\n",
        "    \"\"\"\n",
        "    Adds metadata to the FLAC file.\n",
        "    Includes per-file timestamps (time_coverage_start, time_coverage_end)\n",
        "    and the initial sampling rate.\n",
        "    \"\"\"\n",
        "    audio = FLAC(flac_file_path)\n",
        "    metadata[\"date_created\"] = datetime.utcnow().isoformat()  # Always in UTC\n",
        "    for key, value in metadata.items():\n",
        "        audio[key] = str(value)\n",
        "    audio.save()\n",
        "\n",
        "def flac_to_miniseed(flac_file_path, output_path):\n",
        "    \"\"\"Convert FLAC file to MiniSEED format.\"\"\"\n",
        "    try:\n",
        "        flac_meta = FLAC(flac_file_path)\n",
        "        if 'time_coverage_start' in flac_meta:\n",
        "            start_time = UTCDateTime(flac_meta['time_coverage_start'][0])\n",
        "        elif 'date_created' in flac_meta:\n",
        "            start_time = UTCDateTime(flac_meta['date_created'][0])\n",
        "        else:\n",
        "            start_time = UTCDateTime()\n",
        "    except Exception:\n",
        "        start_time = UTCDateTime()\n",
        "    \n",
        "    flac_audio = AudioSegment.from_file(flac_file_path, format=\"flac\")\n",
        "    samples = np.array(flac_audio.get_array_of_samples())\n",
        "    stream = obspy.Stream()\n",
        "    trace = obspy.Trace(data=samples)\n",
        "    trace.stats.sampling_rate = flac_audio.frame_rate\n",
        "    trace.stats.starttime = start_time\n",
        "    stream.append(trace)\n",
        "    stream.write(output_path, format='MSEED')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# StationXML generation function (simplified - full version in package)\n",
        "\n",
        "def generate_stationxml_obspy(wav_file_name, stationxml_data, duration_seconds, tz_offset):\n",
        "    \"\"\"\n",
        "    Generate EIDA-compliant StationXML file.\n",
        "    Returns the path to the generated XML file.\n",
        "    \"\"\"\n",
        "    # Compute start/end with offset\n",
        "    start_iso, end_iso = generate_start_end_time(wav_file_name, duration_seconds)\n",
        "    start_time = UTCDateTime(start_iso) - timedelta(hours=tz_offset)\n",
        "    end_time = UTCDateTime(end_iso) - timedelta(hours=tz_offset)\n",
        "\n",
        "    # Gather GUI fields\n",
        "    sender = stationxml_data.get(\"sender\", \"\")\n",
        "    source = stationxml_data.get(\"source\", \"\")\n",
        "    net_id = stationxml_data.get(\"network_identifier\", \"\")\n",
        "    network_identifier = (\n",
        "        net_id if net_id.startswith((\"http://\", \"https://\"))\n",
        "        else f\"urn:network_identifier:{net_id}\"\n",
        "    )\n",
        "\n",
        "    # Build Channel, Station, Network via ObsPy\n",
        "    channel = Channel(\n",
        "        code=stationxml_data.get(\"channel_code\", \"\"),\n",
        "        location_code=stationxml_data.get(\"location_code\", \"\"),\n",
        "        latitude=float(stationxml_data.get(\"channel_latitude\", \"0\")),\n",
        "        longitude=float(stationxml_data.get(\"channel_longitude\", \"0\")),\n",
        "        elevation=float(stationxml_data.get(\"channel_elevation\", \"0\")),\n",
        "        depth=float(stationxml_data.get(\"channel_depth\", \"0\")),\n",
        "        azimuth=float(stationxml_data.get(\"azimuth\", \"0\")),\n",
        "        dip=float(stationxml_data.get(\"dip\", \"0\")),\n",
        "        sample_rate=FINAL_SAMPLING_RATE,\n",
        "        start_date=start_time,\n",
        "        end_date=end_time,\n",
        "        response=Response(instrument_sensitivity=InstrumentSensitivity(\n",
        "            value=float(stationxml_data.get(\"sensitivity_value\", \"0\")),\n",
        "            frequency=float(stationxml_data.get(\"sensitivity_frequency\", \"0\")),\n",
        "            input_units=stationxml_data.get(\"input_units_name\", \"\"),\n",
        "            output_units=stationxml_data.get(\"output_units_name\", \"\")\n",
        "        ))\n",
        "    )\n",
        "    if stationxml_data.get(\"sensor_description\"):\n",
        "        channel.description = stationxml_data[\"sensor_description\"]\n",
        "\n",
        "    site = Site(name=stationxml_data.get(\"site_name\", \"\"))\n",
        "    station = Station(\n",
        "        code=stationxml_data.get(\"station_code\", \"\"),\n",
        "        latitude=float(stationxml_data.get(\"latitude\", \"0\")),\n",
        "        longitude=float(stationxml_data.get(\"longitude\", \"0\")),\n",
        "        elevation=float(stationxml_data.get(\"elevation\", \"0\")),\n",
        "        start_date=start_time,\n",
        "        end_date=end_time,\n",
        "        site=site,\n",
        "        channels=[channel]\n",
        "    )\n",
        "    if stationxml_data.get(\"station_description\"):\n",
        "        station.description = stationxml_data[\"station_description\"]\n",
        "\n",
        "    net_desc = stationxml_data.get(\"network_description\", \"\")\n",
        "    net_desc += f\" | Identifier: {network_identifier}\"\n",
        "    network = Network(\n",
        "        code=stationxml_data.get(\"network_code\", \"\"),\n",
        "        description=net_desc,\n",
        "        start_date=start_time,\n",
        "        end_date=end_time,\n",
        "        stations=[station]\n",
        "    )\n",
        "\n",
        "    inventory = Inventory(networks=[network], source=sender)\n",
        "    xml_filename = f\"{os.path.splitext(wav_file_name)[0]}.station.xml\"\n",
        "    inventory.write(xml_filename, format=\"STATIONXML\")\n",
        "\n",
        "    # Post-process with lxml to ensure compliance\n",
        "    xml_parser = etree.XMLParser(remove_blank_text=True)\n",
        "    tree = etree.parse(xml_filename, xml_parser)\n",
        "    root = tree.getroot()\n",
        "    ns_pref = f\"{{{root.nsmap[None]}}}\" if None in root.nsmap else \"\"\n",
        "\n",
        "    # Ensure <Source> before <Sender>\n",
        "    sender_el = root.find(f\"{ns_pref}Sender\")\n",
        "    if source:\n",
        "        src_el = root.find(f\"{ns_pref}Source\") or etree.Element(f\"{ns_pref}Source\")\n",
        "        src_el.text = source\n",
        "        if src_el.getparent() is None and sender_el is not None:\n",
        "            idx = list(root).index(sender_el)\n",
        "            root.insert(idx, src_el)\n",
        "\n",
        "    # Ensure <Sender> text\n",
        "    if sender_el is None:\n",
        "        sender_el = etree.Element(f\"{ns_pref}Sender\")\n",
        "        root.insert(0, sender_el)\n",
        "    sender_el.text = sender\n",
        "\n",
        "    # Remove all <EndDate> children (EIDA standard requirement)\n",
        "    for ed in root.xpath(f\".//{ns_pref}EndDate\"):\n",
        "        ed.getparent().remove(ed)\n",
        "\n",
        "    # Under each <Network>, force <Identifier> first, <Station> last\n",
        "    for net in root.findall(f\"{ns_pref}Network\"):\n",
        "        ident = net.find(f\"{ns_pref}Identifier\")\n",
        "        if ident is None:\n",
        "            ident = etree.Element(f\"{ns_pref}Identifier\")\n",
        "            net.insert(0, ident)\n",
        "        ident.text = network_identifier\n",
        "        net.remove(ident)\n",
        "        net.insert(0, ident)\n",
        "        st = net.find(f\"{ns_pref}Station\")\n",
        "        if st is not None:\n",
        "            net.remove(st)\n",
        "            net.append(st)\n",
        "\n",
        "    tree.write(xml_filename, pretty_print=True, xml_declaration=True, encoding=\"UTF-8\")\n",
        "    return xml_filename\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Main processing function\n",
        "\n",
        "def process_wav_file(file_path, metadata, plot_first=False, tz_offset=0):\n",
        "    \"\"\"\n",
        "    Process a single WAV file: downsample, convert to FLAC, add metadata.\n",
        "    Returns the path to the created FLAC file.\n",
        "    \"\"\"\n",
        "    rate, data = get_wav_info(file_path)\n",
        "    duration_seconds = len(data) / rate\n",
        "    if duration_seconds > 86400:\n",
        "        raise ValueError(f\"File {file_path} has an implausibly long duration ({duration_seconds} seconds).\")\n",
        "    \n",
        "    # Extract file-specific start/end times and initial sampling rate\n",
        "    file_start_time, file_end_time = extract_times_from_wav(file_path)\n",
        "    # Adjust times by the UTC offset so FLAC metadata reflects UTC time\n",
        "    adjusted_start_time = file_start_time - timedelta(hours=tz_offset)\n",
        "    adjusted_end_time = file_end_time - timedelta(hours=tz_offset)\n",
        "    file_metadata = metadata.copy()\n",
        "    file_metadata[\"time_coverage_start\"] = adjusted_start_time.isoformat()\n",
        "    file_metadata[\"time_coverage_end\"] = adjusted_end_time.isoformat()\n",
        "    file_metadata[\"initial_sampling_rate\"] = rate\n",
        "\n",
        "    if rate > FINAL_SAMPLING_RATE:\n",
        "        downsampled_data, filtered_data = downsample_wav(data, rate, FINAL_SAMPLING_RATE)\n",
        "        if plot_first:\n",
        "            plot_signals(data, filtered_data, downsampled_data, rate, FINAL_SAMPLING_RATE)\n",
        "    else:\n",
        "        downsampled_data = data\n",
        "    \n",
        "    downsampled_data = convert_data_format(downsampled_data)\n",
        "    \n",
        "    # Create a temporary WAV file\n",
        "    temp_wav_path = tempfile.mktemp(suffix=\".wav\")\n",
        "    sf.write(temp_wav_path, downsampled_data, FINAL_SAMPLING_RATE)\n",
        "    if not os.path.exists(temp_wav_path):\n",
        "        raise FileNotFoundError(f\"Temporary file {temp_wav_path} was not created.\")\n",
        "    \n",
        "    flac_output_path = file_path.replace('.wav', '.flac').replace('.WAV', '.flac')\n",
        "    convert_wav_to_flac(temp_wav_path, flac_output_path)\n",
        "    add_metadata_to_flac(flac_output_path, file_metadata)\n",
        "    \n",
        "    # Clean up temporary file\n",
        "    if os.path.exists(temp_wav_path):\n",
        "        os.remove(temp_wav_path)\n",
        "    \n",
        "    return flac_output_path\n",
        "\n",
        "def process_files(file_paths, metadata, stationxml_data, tz_offset, plot_preference=False):\n",
        "    \"\"\"\n",
        "    Process multiple WAV files.\n",
        "    Creates FLAC, MiniSEED, and StationXML files for each input.\n",
        "    \"\"\"\n",
        "    total_files = len(file_paths)\n",
        "    successful_files = 0\n",
        "    start_processing_time = time.time()\n",
        "\n",
        "    for index, file_path in enumerate(file_paths):\n",
        "        try:\n",
        "            print(f\"üîç Analyzing file {index + 1} of {total_files} ‚Äî {os.path.basename(file_path)}\")\n",
        "            \n",
        "            # Process to FLAC\n",
        "            flac_output_path = process_wav_file(\n",
        "                file_path,\n",
        "                metadata,\n",
        "                plot_first=(index == 0 and plot_preference),\n",
        "                tz_offset=tz_offset\n",
        "            )\n",
        "\n",
        "            # Convert to MiniSEED\n",
        "            miniseed_output_path = file_path.replace('.wav', '.mseed').replace('.WAV', '.mseed')\n",
        "            flac_to_miniseed(flac_output_path, miniseed_output_path)\n",
        "\n",
        "            # Generate StationXML\n",
        "            rate, data = get_wav_info(file_path)\n",
        "            duration_seconds = len(data) / rate\n",
        "            xml_output_path = generate_stationxml_obspy(\n",
        "                wav_file_name=os.path.basename(file_path),\n",
        "                stationxml_data=stationxml_data,\n",
        "                duration_seconds=duration_seconds,\n",
        "                tz_offset=tz_offset\n",
        "            )\n",
        "\n",
        "            print(f\"‚úÖ Created files for {file_path}:\\n\"\n",
        "                  f\"   ‚Ä¢ FLAC: {flac_output_path}\\n\"\n",
        "                  f\"   ‚Ä¢ MiniSEED: {miniseed_output_path}\\n\"\n",
        "                  f\"   ‚Ä¢ StationXML (.station.xml): {os.path.abspath(xml_output_path)}\")\n",
        "            successful_files += 1\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error processing {file_path}: {e}\")\n",
        "\n",
        "    total_elapsed = time.time() - start_processing_time\n",
        "    elapsed_str = time.strftime('%H:%M:%S', time.gmtime(total_elapsed))\n",
        "    print(f\"\\nüéØ Processed {successful_files} out of {total_files} files successfully.\")\n",
        "    print(f\"‚è±Ô∏è Total processing time: {elapsed_str}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## GUI Application\n",
        "\n",
        "The GUI code is available in the package version (`geo_inquire_processor/gui.py`). \n",
        "\n",
        "To use the GUI in this notebook, you can either:\n",
        "1. Import from the package: `from geo_inquire_processor.gui import Application`\n",
        "2. Or run the standalone version: `python main.py` or `python -m geo_inquire_processor.gui`\n",
        "\n",
        "For a complete standalone notebook version with full GUI code, see the package files.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# To use the GUI, import from the package:\n",
        "# from geo_inquire_processor.gui import Application\n",
        "# app = Application()\n",
        "# app.mainloop()\n",
        "\n",
        "# Or run the main script:\n",
        "# !python main.py\n",
        "\n",
        "print(\"‚úì All processing functions loaded!\")\n",
        "print(\"‚úì Use the package GUI (python main.py) or import functions for programmatic use.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
